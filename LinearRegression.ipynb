{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T21:42:52.948197",
     "start_time": "2017-12-08T21:42:51.736832"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T21:33:10.126218",
     "start_time": "2017-12-08T21:33:10.049339"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self,**kwargs):\n",
    "        self.max_iter = kwargs.get('max_iter') or 1000 # 梯度下降最大迭代次数\n",
    "        self.tol = kwargs.get('tol') or 1e-4 # 梯度下降最小 误差减小值（未使用\n",
    "        self.learning_rate = kwargs.get('learning_rate') or 0.01 # 下降速度\n",
    "        self.task = kwargs.get('task') or 'Classification' #任务类型\n",
    "        self.use_sigmoid = kwargs.get('use_sigmoid') or False #是否使用sigmoid 函数拟合\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        '''\n",
    "        使用梯度下降进行优化\n",
    "        '''\n",
    "        self.X_train = np.append(X_train,np.ones((X_train.shape[0],1)),1) # 补全常数项的值\n",
    "        self.y_train,self.y_map = self.get_y_value(y_train) #处理y值，map 0,1 与真实值对应关系\n",
    "        self.weights,self.error = self.Gradient_Descent(self.X_train,self.y_train) #梯度下降优化系数\n",
    "        self.coef_ = self.weights[:-1] #系数\n",
    "        self.intercept_ = self.weights[-1] #截距\n",
    "    def predict(self,X_test):\n",
    "        '''\n",
    "        预测，矩阵相乘。分类问题结果匹配\n",
    "        '''\n",
    "        estimate_value = X_test*self.coef_+self.intercept_\n",
    "        if self.task == 'Classification':\n",
    "            sigmoid_value = self.sigmoid(estimate_value)\n",
    "            y_one_ = self.y_map.get(1)\n",
    "            return_value = np.full(sigmoid_value.shape,y_one_,dtype=type(y_one_))\n",
    "            return_value[np.argwhere(sigmoid_value<0.5)] = self.y_map.get(0)\n",
    "            return return_value\n",
    "        else:\n",
    "            return estimate_value\n",
    "\n",
    "\n",
    "    def Gradient_Descent(self,X_train,y_train):\n",
    "        labelMat = np.mat(y_train).T #convert to NumPy matrix\n",
    "        m,n = X_train.shape\n",
    "        weights = np.ones((n,1)) # 权重初始值设为1 ，也可设为别的值。\n",
    "        for i in range(self.max_iter):\n",
    "            h = self.get_estimate_value(X_train*weights) # 转化estimate值\n",
    "            error = h - y_train# 计算残差\n",
    "            #box.append(np.abs(error).sum())# 如过下降过慢就停止梯度下降\n",
    "            #if (np.abs(error).sum() - pre_error) < self.tol:\n",
    "                #return weights\n",
    "            weights = weights - self.learning_rate*(X_train.T*error) \n",
    "            #更新权重，这一句对于初学者来说比较难以理解。请对照图形想象理解。\n",
    "        return weights,np.abs(error).sum()\n",
    "    def get_estimate_value(self,raw_estimate):\n",
    "        '''\n",
    "        对估计值转化\n",
    "        '''\n",
    "        if self.task == 'Classification':\n",
    "            return self.sigmoid(raw_estimate)\n",
    "        elif self.task == 'Regression':\n",
    "            if self.use_sigmoid:\n",
    "                return self.sigmoid(raw_estimate)\n",
    "            else:\n",
    "                return raw_estimate\n",
    "    def get_y_value(self,raw_y_train):\n",
    "        '''\n",
    "        对y值转化\n",
    "        '''\n",
    "        if self.task == 'Classification':\n",
    "            cls = np.unique(np.array(raw_y_train))[:2]\n",
    "            new_ytrain = np.ones(raw_y_train.shape)\n",
    "            for i in range(cls.shape[0]):\n",
    "                new_ytrain[np.argwhere(raw_y_train==cls[i])] = i\n",
    "            return new_ytrain,dict(zip([0,1],cls))\n",
    "        else:\n",
    "            if self.use_sigmoid:\n",
    "                return self.sigmoid(raw_y_train),None\n",
    "            else:\n",
    "                return raw_y_train,None\n",
    "            \n",
    "    def sigmoid(self,X):\n",
    "        '''\n",
    "        S型函数\n",
    "        '''\n",
    "        return  1.0/(1+np.exp(-X))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T21:36:50.862130",
     "start_time": "2017-12-08T21:36:50.857232"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    def unit_step(x):\n",
    "        '''\n",
    "        阶跃函数，将此函数替换sigmoid函数，你会发现，函数怎么也不收敛。\n",
    "        '''\n",
    "        if x<0:\n",
    "            return 0\n",
    "        elif x>0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0.5\n",
    "    def unsigmoid(x):\n",
    "        '''\n",
    "        sigmoid函数的逆过程\n",
    "        '''\n",
    "        return -np.log(1/x -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T21:40:06.847963",
     "start_time": "2017-12-08T21:40:06.809808"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    def loadDataSet():\n",
    "        dataMat = []; labelMat = []\n",
    "        fr = open('../Ch05/testSet.txt')\n",
    "        for line in fr.readlines():\n",
    "            lineArr = line.strip().split()\n",
    "            dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
    "            labelMat.append(int(lineArr[2]))\n",
    "        return dataMat,labelMat\n",
    "\n",
    "    a,b = loadDataSet()\n",
    "    a = np.mat(a)\n",
    "    b = np.mat(b).T\n",
    "    LR = LogisticRegression(use_sigmoid=True,learning_rate=0.01,max_iter=1000)\n",
    "    LR.train(a[:,1:],b)\n",
    "    LR.predict(a[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T21:45:53.478844",
     "start_time": "2017-12-08T21:45:53.444638"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    梯度下降错误变化图\n",
    "    '''\n",
    "    box = []\n",
    "    def Gradient_Descent(X_train,y_train):\n",
    "            labelMat = np.mat(y_train).T #convert to NumPy matrix\n",
    "            m,n = X_train.shape\n",
    "            weights = np.ones((n,1)) # 权重初始值设为1 ，也可设为别的值。最后的权重值会变化\n",
    "            for i in range(500):\n",
    "                h = LogisticRegression.get_estimate_value('s',X_train*weights) # 转化estimate值\n",
    "                error = h - y_train# 计算残差\n",
    "                #box.append(np.abs(error).sum())# 如过下降过慢就停止梯度下降\n",
    "                #if (np.abs(error).sum() - pre_error) < self.tol:\n",
    "                    #return weights\n",
    "                weights = weights - 0.001*(X_train.T*error) \n",
    "\n",
    "    Gradient_Descent(a,b)\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.plot(range(len(box)),box)\n",
    "    box[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
